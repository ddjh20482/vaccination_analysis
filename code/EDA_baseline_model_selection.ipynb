{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessar libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# import libraries\n",
    "import data_preparation as dp\n",
    "import visualizations as viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "data = pd.read_csv(\"../data/training_set_features.csv\", index_col = 0)\n",
    "vac = pd.read_csv(\"../data/training_set_labels.csv\", index_col = 0)\n",
    "\n",
    "all_data = data.merge(vac['h1n1_vaccine'], left_index=True, right_index=True)\n",
    "\n",
    "all_data.drop(['doctor_recc_seasonal',\n",
    "               'opinion_seas_vacc_effective',\n",
    "               'opinion_seas_risk',\n",
    "               'opinion_seas_sick_from_vacc'], \n",
    "              axis = 1,\n",
    "              inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dp.missing(all_data)\n",
    "y = X.pop('h1n1_vaccine')\n",
    "\n",
    "for c in X.columns:\n",
    "    X = dp.dummy(X, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Models\n",
    "#### Simple models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score:     85.15%\n",
      "X-test score: 85.17%\n",
      "RMSE:         0.3851\n",
      "\n",
      "Train score\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91     15770\n",
      "           1       0.73      0.49      0.59      4260\n",
      "\n",
      "    accuracy                           0.85     20030\n",
      "   macro avg       0.80      0.72      0.75     20030\n",
      "weighted avg       0.84      0.85      0.84     20030\n",
      "\n",
      "\n",
      "\n",
      "X-test score\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91      5263\n",
      "           1       0.73      0.48      0.58      1414\n",
      "\n",
      "    accuracy                           0.85      6677\n",
      "   macro avg       0.80      0.72      0.74      6677\n",
      "weighted avg       0.84      0.85      0.84      6677\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "\n",
    "dp.scores(X_train, y_train, X_test, y_test, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score:     77.84%\n",
      "X-test score: 78.61%\n",
      "RMSE:         0.4625\n",
      "\n",
      "Train score\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     15770\n",
      "           1       1.00      1.00      1.00      4260\n",
      "\n",
      "    accuracy                           1.00     20030\n",
      "   macro avg       1.00      1.00      1.00     20030\n",
      "weighted avg       1.00      1.00      1.00     20030\n",
      "\n",
      "\n",
      "\n",
      "X-test score\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.87      0.86      5263\n",
      "           1       0.50      0.49      0.49      1414\n",
      "\n",
      "    accuracy                           0.79      6677\n",
      "   macro avg       0.68      0.68      0.68      6677\n",
      "weighted avg       0.79      0.79      0.79      6677\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier()\n",
    "dp.scores(X_train, y_train, X_test, y_test, dtc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More complex models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score:     84.98%\n",
      "X-test score: 84.90%\n",
      "RMSE:         0.3885\n",
      "\n",
      "Train score\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     15770\n",
      "           1       1.00      1.00      1.00      4260\n",
      "\n",
      "    accuracy                           1.00     20030\n",
      "   macro avg       1.00      1.00      1.00     20030\n",
      "weighted avg       1.00      1.00      1.00     20030\n",
      "\n",
      "\n",
      "\n",
      "X-test score\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91      5263\n",
      "           1       0.75      0.43      0.55      1414\n",
      "\n",
      "    accuracy                           0.85      6677\n",
      "   macro avg       0.81      0.70      0.73      6677\n",
      "weighted avg       0.84      0.85      0.83      6677\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "dp.scores(X_train, y_train, X_test, y_test, rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score:     85.16%\n",
      "X-test score: 85.08%\n",
      "RMSE:         0.3862\n",
      "\n",
      "Train score\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91     15770\n",
      "           1       0.72      0.49      0.58      4260\n",
      "\n",
      "    accuracy                           0.85     20030\n",
      "   macro avg       0.80      0.72      0.75     20030\n",
      "weighted avg       0.84      0.85      0.84     20030\n",
      "\n",
      "\n",
      "\n",
      "X-test score\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91      5263\n",
      "           1       0.72      0.49      0.58      1414\n",
      "\n",
      "    accuracy                           0.85      6677\n",
      "   macro avg       0.80      0.72      0.74      6677\n",
      "weighted avg       0.84      0.85      0.84      6677\n",
      "\n"
     ]
    }
   ],
   "source": [
    "abc = AdaBoostClassifier()\n",
    "dp.scores(X_train, y_train, X_test, y_test, abc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score:     85.29%\n",
      "X-test score: 85.41%\n",
      "RMSE:         0.3819\n",
      "\n",
      "Train score\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.91     15770\n",
      "           1       0.75      0.50      0.60      4260\n",
      "\n",
      "    accuracy                           0.86     20030\n",
      "   macro avg       0.81      0.73      0.76     20030\n",
      "weighted avg       0.85      0.86      0.85     20030\n",
      "\n",
      "\n",
      "\n",
      "X-test score\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91      5263\n",
      "           1       0.74      0.48      0.58      1414\n",
      "\n",
      "    accuracy                           0.85      6677\n",
      "   macro avg       0.81      0.72      0.75      6677\n",
      "weighted avg       0.84      0.85      0.84      6677\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gbc = GradientBoostingClassifier()\n",
    "dp.scores(X_train, y_train, X_test, y_test, gbc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest model is selected for the hyperparameter tuning as it has the highest recall score for 0's (not vaccinated). Decision tree is selected for the one of baseline model as random forest idea is based on decision tree method."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
